{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running a Grid\n",
    "\n",
    "A common task is to run UCLCHEM over a grid of parameter combinations. This notebook sets up a simple approach to doing so for regular grids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import uclchem\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Simple Grid\n",
    "### Define Parameter Space\n",
    "First, we define our parameter space. We do this by using numpy and pandas to produce a table of all possible combinations of some parameters of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part can be substituted with any choice of grid\n",
    "# here we just vary the density, temperature and zeta\n",
    "temperatures = np.linspace(10, 50, 3)\n",
    "densities = np.logspace(4, 6, 3)\n",
    "zetas = np.logspace(1, 3, 3)\n",
    "\n",
    "# meshgrid will give all combinations, then we shape into columns and put into a table\n",
    "parameterSpace = np.asarray(np.meshgrid(temperatures, densities, zetas)).reshape(3, -1)\n",
    "model_table = pd.DataFrame(parameterSpace.T, columns=[\"temperature\", \"density\", \"zeta\"])\n",
    "\n",
    "# keep track of where each model output will be saved and make sure that folder exists\n",
    "model_table[\"outputFile\"] = model_table.apply(\n",
    "    lambda row: f\"../grid_folder/{row.temperature}_{row.density}_{row.zeta}.csv\", axis=1\n",
    ")\n",
    "print(f\"{model_table.shape[0]} models to run\")\n",
    "if not os.path.exists(\"../grid_folder\"):\n",
    "    os.makedirs(\"../grid_folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the model\n",
    "Next, we need a function that will run our model. We write a quick function that takes a row from our dataframe and uses it to populate a parameter dictionary for UCLCHEM and then run a cloud model. We can then map our dataframe to that function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(row):\n",
    "    # basic set of parameters we'll use for this grid.\n",
    "    ParameterDictionary = {\n",
    "        \"endatfinaldensity\": False,\n",
    "        \"freefall\": False,\n",
    "        \"initialDens\": row.density,\n",
    "        \"initialTemp\": row.temperature,\n",
    "        \"zeta\": row.zeta,\n",
    "        \"outputFile\": row.outputFile,\n",
    "        \"finalTime\": 1.0e6,\n",
    "        \"baseAv\": 10,\n",
    "    }\n",
    "    result = uclchem.model.cloud(param_dict=ParameterDictionary)\n",
    "    return result[0]  # just the integer error code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Grid \n",
    "\n",
    "#### The Simple Way\n",
    "We can use pandas apply to simply pass each row to our helper function in turn. This will take some time since we're running the models one by one. I'll use the `head` function just to run five rows as an example here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "result = model_table.head().apply(run_model, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Fast Way\n",
    "Alternatively, we can use multiprocessing to run the models in parallel. That will allow us to run many models simulataneously and make use of all the cores available on our machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = Parallel(n_jobs=4, verbose=100)(\n",
    "    delayed(run_model)(row) for idx, row in model_table.iterrows()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Your Grid\n",
    "After running, we should do two things. First, let's add `results` to our dataframe as a new column. Positive results mean a successful UCLCHEM run and negative ones are unsuccessful. Then we can run each model through `check_element_conservation` to check the integration was successful. We'll use both these things to flag models that failed in some way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def element_check(output_file):\n",
    "    df = uclchem.analysis.read_output_file(output_file)\n",
    "    # get conservation values\n",
    "    conserves = uclchem.analysis.check_element_conservation(df)\n",
    "    # check if any error is greater than 1%\n",
    "    return all([float(x[:-1]) < 1 for x in conserves.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_table[\"run_result\"] = results\n",
    "model_table[\"elements_conserved\"] = model_table[\"outputFile\"].map(element_check)\n",
    "# check both conditions are met\n",
    "model_table[\"Successful\"] = (model_table.run_result >= 0) & (\n",
    "    model_table.elements_conserved\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex Grid\n",
    "\n",
    "The above was straightforward enough but what about a modelling a grid of shocks? Not only do we want to loop over relevant parameters, we also need to run a few preliminary models to give ourselves starting abundances. We'll start by defining two helper functions, one to run our preliminary cloud and one to run the shock.\n",
    "\n",
    "Let's further imagine that we want to obtain the abundances of several species at the end of the model. We can use the `out_species` parameter to specify which species we want to track and return them to our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_species = [\"CO\", \"H2O\", \"CH3OH\"]\n",
    "\n",
    "\n",
    "def run_prelim(density):\n",
    "    # basic set of parameters we'll use for this grid.\n",
    "    ParameterDictionary = {\n",
    "        \"endatfinaldensity\": True,\n",
    "        \"freefall\": True,\n",
    "        \"initialDens\": 1e2,\n",
    "        \"finalDens\": density,\n",
    "        \"initialTemp\": 10.0,\n",
    "        \"abundSaveFile\": f\"../grid_folder/starts/{density:.0f}.csv\",\n",
    "        \"baseAv\": 1,\n",
    "    }\n",
    "    result = uclchem.model.cloud(param_dict=ParameterDictionary)\n",
    "    return result\n",
    "\n",
    "\n",
    "def run_model(row):\n",
    "    # basic set of parameters we'll use for this grid.\n",
    "    ParameterDictionary = {\n",
    "        \"endatfinaldensity\": False,\n",
    "        \"freefall\": False,\n",
    "        \"initialDens\": row.density,\n",
    "        \"initialTemp\": 10.0,\n",
    "        \"outputFile\": row.outputFile,\n",
    "        \"abundLoadFile\": f\"../grid_folder/starts/{row.density:.0f}.csv\",\n",
    "        \"finalTime\": 1.0e5,\n",
    "        \"abstol_factor\": 1e-18,\n",
    "        \"reltol\": 1e-12,\n",
    "        \"baseAv\": 1,\n",
    "    }\n",
    "    result = uclchem.model.cshock(\n",
    "        row.shock_velocity, param_dict=ParameterDictionary, out_species=out_species\n",
    "    )\n",
    "    # First check UCLCHEM's result flag to seeif it ran succesfully, if it is return the abundances\n",
    "    if result[0] == 0:\n",
    "        return result[:]\n",
    "    # if not, return NaNs because model failed\n",
    "    else:\n",
    "        return [np.nan] * len(out_species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define our parameter space again. We'll create two folders, one to store a set of initial abundances for each starting density in our model and another to store our shock outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part can be substituted with any choice of grid\n",
    "# here we just combine various initial and final densities into an easily iterable array\n",
    "shock_velocities = np.linspace(10, 50, 3)\n",
    "densities = np.logspace(4, 6, 3)\n",
    "\n",
    "parameterSpace = np.asarray(np.meshgrid(shock_velocities, densities)).reshape(2, -1)\n",
    "model_table = pd.DataFrame(parameterSpace.T, columns=[\"shock_velocity\", \"density\"])\n",
    "model_table[\"outputFile\"] = model_table.apply(\n",
    "    lambda row: f\"../grid_folder/shocks/{row.shock_velocity}_{row.density}.csv\", axis=1\n",
    ")\n",
    "print(f\"{model_table.shape[0]} models to run\")\n",
    "\n",
    "for folder in [\"starts\", \"shocks\"]:\n",
    "    if not os.path.exists(f\"../grid_folder/{folder}\"):\n",
    "        os.makedirs(f\"../grid_folder/{folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then run our preliminary models followed by our science models. The science models will return the abundances at the final time step of each run so we can unpack those directly to our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=4, verbose=100)(\n",
    "    delayed(run_prelim)(dens) for dens in densities\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=4, verbose=100)(\n",
    "    delayed(run_model)(row) for idx, row in model_table.iterrows()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_table[[\"Result\", \"Dissipation Time\"] + out_species] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "There are many ways to run grids of models and users will naturally develop their own methods. This notebook is just a simple example of how to run UCLCHEM for many parameter combinations whilst producing a useful output (the model_table) to keep track of all the combinations that were run. In a real script, we'd save the model file to csv at the end.\n",
    "\n",
    "For much larger grids, it's recommended that you find a way to make your script robust to failure. Over a huge range of parameters, it is quite likely UCLCHEM will hit integration trouble for at least a few parameter combinations. Very occasionally, UCLCHEM will get caught in a loop where it fails to integrate and cannot adjust its strategy to manage it. This isn't a problem for small grids as the model can be stopped and the tolerances adjusted. However, for very large grids, you may end up locking all threads as they each get stuck on a different model. The best solution we've found for this case is to add a check so that models in your dataframe are skipped if their file already exists, this allows you to stop and restart the grid script as needed.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "UCLCHEM 3.4.0 Release Candidate",
   "language": "python",
   "name": "uclchem_rc3.4.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
